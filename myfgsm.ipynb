{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sugandh-Mishra/attacks/blob/main/myfgsm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWX8607Nk7ac"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras import layers, models, datasets\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhPt703fqH7z"
      },
      "outputs": [],
      "source": [
        "def train_model():\n",
        "    (train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "    train_images = train_images.reshape((60000, 28, 28, 1)) / 255.0\n",
        "    test_images = test_images.reshape((10000, 28, 28, 1)) / 255.0\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))\n",
        "    \n",
        "    return model,test_images,test_labels\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cTPmxesqElN"
      },
      "outputs": [],
      "source": [
        "def fgsm_attack(model, image, epsilon, data_grad):\n",
        "    sign_data_grad = tf.sign(data_grad)\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    perturbed_image = tf.clip_by_value(perturbed_image, 0, 1)\n",
        "    return perturbed_image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnV-Sk9cqDRy"
      },
      "outputs": [],
      "source": [
        "def generate_perturbed_images(model, test_images, test_labels, epsilon):\n",
        "    perturbed_images = []\n",
        "    for i in range(len(test_images)):\n",
        "        # Get the i-th test image and label\n",
        "        image, label = test_images[i:i+1], test_labels[i:i+1]\n",
        "        # Convert the image and label to tensors\n",
        "        image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "        label = tf.convert_to_tensor(label, dtype=tf.int64)\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        image = tf.Variable(image, trainable=True)\n",
        "        # Forward pass the data through the model\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = model(image)\n",
        "            # Calculate the loss\n",
        "            loss = tf.keras.losses.sparse_categorical_crossentropy(label, output)\n",
        "        # Calculate the gradients of the loss with respect to the image\n",
        "        gradient = tape.gradient(loss, image)\n",
        "\n",
        "        perturbed_image = fgsm_attack(model, image, epsilon, gradient)\n",
        "        # Append the perturbed image to the list\n",
        "        perturbed_images.append(perturbed_image.numpy())\n",
        "    # Convert the list of perturbed images to a NumPy array\n",
        "    perturbed_images = np.array(perturbed_images)\n",
        "    \n",
        "    return perturbed_images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlL-pgHvp8Gy"
      },
      "outputs": [],
      "source": [
        "                    \n",
        "def test(model, test_images, test_labels, epsilon):\n",
        "    test_loss = 0\n",
        "    correct_original = 0\n",
        "    correct_attacked = 0\n",
        "    \n",
        "    original_images = []\n",
        "    attacked_images = []\n",
        "    \n",
        "    for i in range(len(test_images)):\n",
        "        # Get the i-th test image and label\n",
        "        image, label = test_images[i:i+1], test_labels[i:i+1]\n",
        "        # Convert the image and label to tensors\n",
        "        image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "        label = tf.convert_to_tensor(label, dtype=tf.int64)\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        image = tf.Variable(image, trainable=True)\n",
        "        # Forward pass the data through the model\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = model(image)\n",
        "            # Calculate the loss\n",
        "            loss = tf.keras.losses.sparse_categorical_crossentropy(label, output)\n",
        "        # Calculate the gradients of the loss with respect to the image\n",
        "        gradient = tape.gradient(loss, image)\n",
        "        # Call FGSM Attack\n",
        "        perturbed_image = fgsm_attack(model,image, epsilon, gradient)\n",
        "        # Re-classify the perturbed image\n",
        "        output_original = model(image)\n",
        "        output_attacked = model(perturbed_image)\n",
        "        # Calculate the loss on the original and attacked images\n",
        "        loss_original = tf.keras.losses.sparse_categorical_crossentropy(label, output_original)\n",
        "        loss_attacked = tf.keras.losses.sparse_categorical_crossentropy(label, output_attacked)\n",
        "        # Add the losses to the test set loss\n",
        "        test_loss += loss_original.numpy().mean()\n",
        "        # Get the index of the max probability\n",
        "        pred_original = tf.argmax(output_original, axis=1)\n",
        "        pred_attacked = tf.argmax(output_attacked, axis=1)\n",
        "        # Check if the predictions are correct\n",
        "        correct_original += tf.reduce_sum(tf.cast(pred_original == label, tf.int32)).numpy()\n",
        "        correct_attacked += tf.reduce_sum(tf.cast(pred_attacked == label, tf.int32)).numpy()\n",
        "        # Store the original and attacked images for comparison\n",
        "        original_images.append(image.numpy())\n",
        "        attacked_images.append(perturbed_image.numpy())\n",
        "        \n",
        "    # Calculate the final test set loss and accuracy\n",
        "    test_loss /= len(test_images)\n",
        "    accuracy_original = 100. * correct_original / len(test_images)\n",
        "    accuracy_attacked = 100. * correct_attacked / len(test_images)\n",
        "    \n",
        "    return test_loss, accuracy_original, accuracy_attacked, original_images, attacked_images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtwuvaMpp4Jn",
        "outputId": "3004db0e-d738-42a0-92aa-fbd048daa650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1285 - accuracy: 0.9609 - val_loss: 0.0401 - val_accuracy: 0.9873\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.0349 - val_accuracy: 0.9886\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0298 - accuracy: 0.9907 - val_loss: 0.0382 - val_accuracy: 0.9881\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.0307 - val_accuracy: 0.9903\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.0291 - val_accuracy: 0.9909\n"
          ]
        }
      ],
      "source": [
        "model,test_images,test_labels = train_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_5LIcnSp3XA",
        "outputId": "ac8210f9-0bee-4d02-82a3-5bbb43a1bc60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.0291\n",
            "Original accuracy: 99.09%\n",
            "Attacked accuracy: 99.03%\n",
            "Test loss: 0.0291\n",
            "Original accuracy: 99.09%\n",
            "Attacked accuracy: 98.72%\n",
            "Test loss: 0.0291\n",
            "Original accuracy: 99.09%\n",
            "Attacked accuracy: 95.34%\n",
            "Test loss: 0.0291\n",
            "Original accuracy: 99.09%\n",
            "Attacked accuracy: 85.90%\n",
            "Test loss: 0.0291\n",
            "Original accuracy: 99.09%\n",
            "Attacked accuracy: 47.77%\n",
            "Test loss: 0.0291\n",
            "Original accuracy: 99.09%\n",
            "Attacked accuracy: 12.15%\n",
            "Test loss: 0.0291\n",
            "Original accuracy: 99.09%\n",
            "Attacked accuracy: 9.22%\n",
            "Test loss: 0.0291\n",
            "Original accuracy: 99.09%\n",
            "Attacked accuracy: 9.46%\n"
          ]
        }
      ],
      "source": [
        "# Test the model with epsilon \n",
        "epsilon = [0.001,0.01,0.05,0.1,0.2,0.4,0.5,0.6]\n",
        "for i in epsilon:\n",
        "  test_loss, accuracy_original, accuracy_attacked, original_images, attacked_images = test(model, test_images, test_labels, i)\n",
        "  # Print the results\n",
        "  print(f\"Test loss: {test_loss:.4f}\")\n",
        "  print(f\"Original accuracy: {accuracy_original:.2f}%\")\n",
        "  print(f\"Attacked accuracy: {accuracy_attacked:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs2H0y/pZ1ZVSgk1prPtmX",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}